{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering (Question 1 of the Homework)\n",
    "\n",
    "The goal of this notebook is to describe the set of data features used for Machine Learning modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Supervised or Unsupervised Learning?\n",
    "\n",
    "As discussed in the [`next_steps` notebook](../EDA/next_steps.ipynb), the goal of this project is to predict the **Primary Energy consumption per Capita** using regression algorithms. Regressions algorithm are supervised Machine Learning algorithms.\n",
    "\n",
    "Inputs and outputs features have already been determined in [this notebook](../EDA/next_steps.ipynb):\n",
    "\n",
    "| Features | Factor | Cofactor | Response |\n",
    "| ----------------- | :---------: | :---------: | :---------: |\n",
    "| Access to electricity (% of population)                           | X | | |\n",
    "| Access to clean fuels for cooking                                 | X | | |\n",
    "| Renewable energy share in the total final energy consumption (%)  | X | | |\n",
    "| Primary energy consumption per capita (kWh/person)                | |  | X |\n",
    "| GDP per capita                                                    | X | | |\n",
    "\n",
    "We do not have any cofactors because I have picked only features that are highly correlated with the response variable (Primary energy consumption per capita)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Features Details\n",
    "\n",
    "Based on the Exploratory Data Analysis, I have saved 3 different datasets to train my regression models:\n",
    "\n",
    "1. [`pe_dataset.csv`](../data/pe/pe_dataset.csv): This dataset contains all the rows of the main dataset but has only targetted features (inputs and outputs + country name and year).\n",
    "2. [`normalized_pe_dataset.csv`](../data/pe/normalized_pe_dataset.csv): Same as `pe_dataset.csv` but with normalized numerical features.\n",
    "3. [`normalized_pe_dataset_without_outliers.csv`](../data/pe/normalized_pe_dataset_without_outliers.csv): Same as `normalized_pe_dataset.csv` but without top outliers.\n",
    "\n",
    "It will be interesting to watch how the models perform on each dataset. Data features were not collected from experiments or simulations but based on administratives sources, measurements and surveys. More details about that in the [dataset description notebook](../EDA/dataset_description.ipynb).\n",
    "\n",
    "No Machine Learning models, no data augmentation and PCA have been used to derive the features. Daata features are the raw values from the main dataset that has only been normalized for the second and third datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Features types\n",
    "\n",
    "As discussed in the [`datset_sampling` notebook](../EDA/dataset_sampling.ipynb), all of the features (inputs and outputs) are modeled as continuous distributions (I don't take into account the country name and the year which are not relevant). Moreover, all of the features are numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3649 entries, 0 to 3648\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                                            Non-Null Count  Dtype  \n",
      "---  ------                                                            --------------  -----  \n",
      " 0   Entity                                                            3649 non-null   object \n",
      " 1   Year                                                              3649 non-null   int64  \n",
      " 2   Access to electricity (% of population)                           3639 non-null   float64\n",
      " 3   Access to clean fuels for cooking                                 3480 non-null   float64\n",
      " 4   Renewable energy share in the total final energy consumption (%)  3455 non-null   float64\n",
      " 5   Primary energy consumption per capita (kWh/person)                3649 non-null   float64\n",
      " 6   gdp_per_capita                                                    3367 non-null   float64\n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 199.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_pe = pd.read_csv(\"../data/pe/pe_dataset.csv\")\n",
    "df_pe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dataset is devided by countries, doing a hot deck imputation directly on all the dataset would be a mistake. For instance, data for *France* and for *Yemen* are not comparable. In one hand we have a developed country and in the other hand we have a developing country. Therefore, it is better to do a hot deck imputation for each country separately.\n",
    "\n",
    "Due to the fact that we don't have a huge amount of missing values that will be imputed, I have decided to use an interpolation startegy for each country (it might not change a lot the distribution). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df_pe['Entity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in countries:\n",
    "    df_pe[df_pe['Entity'] == country] = df_pe[df_pe['Entity'] == country].interpolate(method='linear', limit_direction='forward', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For other missing values, we will drop the rows that contain them. After this step, we still have more than 3,000 rows which is enough to train our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3193 entries, 2 to 3648\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                                            Non-Null Count  Dtype  \n",
      "---  ------                                                            --------------  -----  \n",
      " 0   Entity                                                            3193 non-null   object \n",
      " 1   Year                                                              3193 non-null   int64  \n",
      " 2   Access to electricity (% of population)                           3193 non-null   float64\n",
      " 3   Access to clean fuels for cooking                                 3193 non-null   float64\n",
      " 4   Renewable energy share in the total final energy consumption (%)  3193 non-null   float64\n",
      " 5   Primary energy consumption per capita (kWh/person)                3193 non-null   float64\n",
      " 6   gdp_per_capita                                                    3193 non-null   float64\n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 199.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_pe = df_pe.dropna(axis=0)\n",
    "df_pe.to_csv(\"../data/pe/cleaned/pe_dataset.csv\", index=False)\n",
    "df_pe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, countries):\n",
    "    for country in countries:\n",
    "        df[df['Entity'] == country] = df[df['Entity'] == country].interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "    return df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3193 entries, 2 to 3648\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                                            Non-Null Count  Dtype  \n",
      "---  ------                                                            --------------  -----  \n",
      " 0   Entity                                                            3193 non-null   object \n",
      " 1   Year                                                              3193 non-null   int64  \n",
      " 2   Access to electricity (% of population)                           3193 non-null   float64\n",
      " 3   Access to clean fuels for cooking                                 3193 non-null   float64\n",
      " 4   Renewable energy share in the total final energy consumption (%)  3193 non-null   float64\n",
      " 5   Primary energy consumption per capita (kWh/person)                3193 non-null   float64\n",
      " 6   gdp_per_capita                                                    3193 non-null   float64\n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 199.6+ KB\n"
     ]
    }
   ],
   "source": [
    "normalized_df_pe = pd.read_csv(\"../data/pe/normalized_pe_dataset.csv\")\n",
    "normalized_df_pe = clean_data(normalized_df_pe, countries)\n",
    "normalized_df_pe.to_csv(\"../data/pe/cleaned/normalized_pe_dataset.csv\", index=False)\n",
    "normalized_df_pe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3009 entries, 2 to 3465\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                                            Non-Null Count  Dtype  \n",
      "---  ------                                                            --------------  -----  \n",
      " 0   Entity                                                            3009 non-null   object \n",
      " 1   Year                                                              3009 non-null   int64  \n",
      " 2   Access to electricity (% of population)                           3009 non-null   float64\n",
      " 3   Access to clean fuels for cooking                                 3009 non-null   float64\n",
      " 4   Renewable energy share in the total final energy consumption (%)  3009 non-null   float64\n",
      " 5   Primary energy consumption per capita (kWh/person)                3009 non-null   float64\n",
      " 6   gdp_per_capita                                                    3009 non-null   float64\n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 188.1+ KB\n"
     ]
    }
   ],
   "source": [
    "normalized_df_pe_without_outliers = pd.read_csv(\"../data/pe/normalized_pe_dataset_without_outliers.csv\")\n",
    "normalized_df_pe_without_outliers = clean_data(normalized_df_pe_without_outliers, countries)\n",
    "normalized_df_pe_without_outliers.to_csv(\"../data/pe/cleaned/normalized_pe_dataset_without_outliers.csv\", index=False)\n",
    "normalized_df_pe_without_outliers.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
